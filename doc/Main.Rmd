---
title: "Facial Emotion Recognition by PCA and LDA"
author: "Group 7"
date: "3/18/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, message=FALSE, echo=F}
if(!require("EBImage")){
  source("https://bioconductor.org/biocLite.R")
  biocLite("EBImage")
}
if(!require("R.matlab")){
  install.packages("R.matlab")
}
if(!require("readxl")){
  install.packages("readxl")
}

if(!require("dplyr")){
  install.packages("dplyr")
}
if(!require("readxl")){
  install.packages("readxl")
}

if(!require("ggplot2")){
  install.packages("ggplot2")
}

if(!require("caret")){
  install.packages("caret")
}

if(!require("MASS")){
  install.packages("MASS")
}

if(!require("parallel")){
  install.packages("parallel")
}

if(!require("data.table")){
  install.packages("data.table")
}

if(!require("gbm")){
  install.packages("gbm")
}

if(!require("e1071")){
  install.packages("e1071")
}
if(!require("xgboost")){
  install.packages("xgboost")
}

if(!require("caret")){
  install.packages("caret")
}
if(!require("caTools")){
  install.packages("caTools")
}
if(!require("kernlab")){
  install.packages("kernlab")
}
if(!require("Matrix")){
  install.packages("Matrix")
}


library(R.matlab)
library(readxl)
library(dplyr)
library(EBImage)
library(ggplot2)
library(caret)
library(MASS)
library(data.table)
library(parallel)
library(gbm)
library(e1071)
library(xgboost)
library(caret)
library(caTools)
library(kernlab)
library(Matrix)
```



```{r exp_setup}
setwd("~/Desktop/Spring2020-Project3-ads-spring2020-project3-group7/doc/")
train_dir <- "../data/train_set/"
train_image_dir <- paste(train_dir, "images/", sep="")
train_pt_dir <- paste(train_dir,  "points/", sep="")
train_label_path <- paste(train_dir, "label.csv", sep="")

run.cv=FALSE # run cross-validation on the training set
K <- 5  # number of CV folds
run.feature.train=TRUE # process features for training set
```

## **Step 2: import data and train-test split**

We splitted the data to 2000 (80%) for training and 50 (20%) for test.

```{r}
#train-test split
set.seed(10)
info <- read.csv(train_label_path)
n <- nrow(info)
n_train <- round(n*(4/5), 0)
train_idx <- sample(info$Index, n_train, replace = F)
test_idx <- setdiff(info$Index,train_idx)
```


```{r}
#function to read fiducial points
#input: index
#output: matrix of fiducial points corresponding to the index
n_files <- length(list.files(train_image_dir))
readMat.matrix <- function(index){
     return(round(readMat(paste0(train_pt_dir, sprintf("%04d", index), ".mat"))[[1]],0))
}

#load fiducial points
fiducial_pt_list <- lapply(1:n_files, readMat.matrix)
save(fiducial_pt_list, file="../output/fiducial_pt_list.RData")
```

```{r}
load("../output/fiducial_pt_list.RData")
```


## **Step 3: baseline model**

### Step 3.1: feature construction

This step is converting 78 fiducial points to distances as 6006 features (3003 horizontal distances and 3003 vertical distances).

The time for training and test feature construction are as below (about 1.5s and 0.1s):

```{r}
if(run.feature.train){
  
  source("../lib/feature.R")
  base.feature.construction.start = proc.time()
  tm_feature_train <- NA
  dat_train_base <- feature(fiducial_pt_list, train_idx)
  base.feature.construction.train.end = proc.time()
  
  tm_feature_test <- NA
  dat_test_base <- feature(fiducial_pt_list, test_idx)
  base.feature.construction.test.end = proc.time()
  
  #time for training feature construction
  print(base.feature.construction.train.end - base.feature.construction.start)
  #time for test feature construction
  print(base.feature.construction.test.end - base.feature.construction.train.end)
  
  save(dat_train_base, file="../output/feature_train_base.RData")
  save(dat_test_base, file="../output/feature_test_base.RData")

}
```


### Step 3.2: load feature

```{r}
load("../output/feature_train_base.Rdata")
load("../output/feature_test_base.Rdata")
```

### Step 3.3: baseline model: gradient boosting machine

We use gradient boosting machine with stumps for our baseline model. The training dataset is $2000\times6006$ features and an emotion index list with length 2000 of 22 types as response. The time to train the baseline model is as below (about 307s):

# 我们将带有树桩的梯度提升机gbm用于我们的基线模型。 训练数据集是$ 2000 \ times6006 $个特征和一个情感索引列表，长度为2000的22种类型作为响应。 训练基线模型的时间如下（大约307s）

#训练机train

```{r}
#gbm classifier
base.train.model.start = proc.time()
baseline=gbm(emotion_idx~. ,data =dat_train_base ,distribution = "multinomial",n.trees = 100,
             shrinkage = 0.02,n.minobsinnode = 15,cv.folds = 5)
base.train.model.end = proc.time()
#time for training the baseline model
print(base.train.model.end - base.train.model.start)
```

This is our prediction part for gradient boosting model. The test dataset has the same variables as training data but with only 500 samples. It takes around 9.6s to predict and the test results are as below. The testing accuracy is 43%.

# 这是我们对梯度增强模型的预测部分。 测试数据集具有与训练数据相同的变量，但只有500个样本。 大约需要9.6s进行预测，测试结果如下。 测试精度为43％。

#测试集test

```{r}
#predict on test data
base.test.start = proc.time()
baseline.pred = predict.gbm(object = baseline,
                   newdata = dat_test_base,
                   n.trees = 100,
                   type = "response")
base.test.end = proc.time()
#time for testing the baseline model
print(base.test.end - base.test.start)
#prediction result
baseline.labels = colnames(baseline.pred)[apply(baseline.pred, 1, which.max)]
baseline.cm = confusionMatrix(dat_test_base$emotion_idx, as.factor(as.numeric(baseline.labels)))
print(baseline.cm$byClass[1])
print(baseline.cm$table)
```

### **Step 4: our improved model**

### Step 4.1: construct features and responses
```{r}

feature.construction.start = proc.time()
#delete the duplicated right face
leftmid_idx <- c(1:9,19:26,35:44,50:52,56:59,62,63,64:71)
fiducial_pt_list_lm <- lapply(fiducial_pt_list, function(mat){return(mat[leftmid_idx,])})

#306 duplicates index
n.m <- 44
middle <- c(18:21,27,30,31,34,35,44)
d <- rep(1, 946)
m=matrix(rep(0, n.m^2),n.m,n.m,byrow=T)
k=1
for(i in 1:(n.m-1))for(j in (i+1):n.m){
  m[i,j] <- m[j,i] <- d[k]
  k=k+1
}
m

m[middle,] <- -1
m[,middle] <- -1
m[middle,middle] <- -2
m
ind <- c()
k=1
for(i in 1:(n.m-1)) for(j in (i+1):n.m){
  if(m[j,i] == -1) ind <- c(ind, k)
  k=k+1
}
#关于k的组合，这么多行
#中间含有的所有的k的东西，就是中间的值
ind
load("../output/new_index(1).RData")
dup_horiz <- new_index
dup_horiz=as.numeric(dup_horiz)
dup_horiz
```

```{r feature}
if(run.feature.train){

  source("../lib/feature.R")
  tm_feature_train <- NA
  dat_train <- feature(fiducial_pt_list_lm, train_idx)
  feature.construction.train.end = proc.time()
  
  dat_train <- dat_train[,-dup_horiz]
  feature.construction.train.end = proc.time()
  
  tm_feature_test <- NA
  dat_test <- feature(fiducial_pt_list_lm, test_idx)
  feature.construction.test.end = proc.time()
  
  dat_test <- dat_test[,-dup_horiz]
  feature.construction.test.end = proc.time()
  
  #time for training feature construction
  print(feature.construction.train.end - feature.construction.start)
  #time for test feature construction
  print(feature.construction.test.end - feature.construction.train.end)
  
  save(dat_train, file="../output/feature_train.RData")
  save(dat_test, file="../output/feature_test.RData")

}
```

###  load features

```{r}
load("../output/feature_train.RData")
load("../output/feature_test.RData")
```

###pca(linear method)
```{r}
n.pca.list <- c(30,50,75,120,150,200)
dim(dat_train)
dim(dat_test)
train.model.start = proc.time()

pca <- prcomp(dat_train[,-1514], cor=T)
pca
train_pca <- data.frame(pca$x[,1:50]) 
train_pca


pca2=predict(pca,dat_test[,-1514])
pca2
test_pca=data.frame(pca2[, 1:50])
test_pca


train_index<- dat_train[1514]
dat_train_pca <- cbind(train_pca, train_index)
dat_train_pca

test_index<- dat_test[1514]
dat_test_pca <- cbind(test_pca, test_index)
dat_test_pca

##training time 

lda.model_pca <- lda(emotion_idx ~ ., data=dat_train_pca) 
train.model.end = proc.time()
#time for training the model
print(train.model.end - train.model.start)
```

###pca(linear method)

```{r}
n.pca.list <- c(30,50,80,100,150,200)
dim(dat_train)
dim(dat_test)

train_time_pca=function(n.pca.list=n.pca.list)
for(i in 1:length(n.pca.list)){
  train.model.start = proc.time()
pca <- prcomp(dat_train[,-1514], cor=T)
train_pca <- data.frame(pca$x[,1:n.pca.list[i]]) 

pca2=predict(pca,dat_test[,-1514])
test_pca=data.frame(pca2[, 1:n.pca.list[i]])

train_index<- dat_train[1514]
dat_train_pca <- cbind(train_pca, train_index)

test_index<- dat_test[1514]
dat_test_pca <- cbind(test_pca, test_index)

##training time 

lda.model_pca <- lda(emotion_idx ~ ., data=dat_train_pca) 
#time for training the model
train.model.end = proc.time()

#time for testing the model
test.model.start = proc.time()
lda.test.pred_pca = predict(lda.model_pca, dat_test_pca[-dim(dat_test_pca)[2]])
test.model.end = proc.time()

#test accuracy
test_accuracy=confusionMatrix(lda.test.pred_pca$class, dat_test_pca$emotion_idx)$overall[1]

print(list(l1=train.model.end - train.model.start,
           l2=test.model.end - test.model.start,
           l3=test_accuracy))
}
train_time_pca(n.pca.list)
```

```{r}
#considering all the results including training time, testing time and accuracy,
#we choose 50 principle components.

train_pca_final <- data.frame(pca$x[,1:50]) 
dat_train_pca_final=cbind(train_pca_final, train_index)
pca2=predict(pca,dat_test[,-1514])
test_pca_final=data.frame(pca2[, 1:50])


dat_test_pca_final=cbind(test_pca_final, test_index)
dim(dat_test_pca_final)

save(dat_train_pca_final, file="../output/feature_pca_train.RData")
save(dat_test_pca_final, file="../output/feature_pca_test.RData")
```

```{r exp_setup}
run.cv=TRUE # run cross-validation on the training set
K <- 5  # number of CV folds
run.feature.train=FALSE # process features for training set
run.test=TRUE # run evaluation on an independent test set
run.feature.test=TRUE # process features for test set
run.feature.test.test=FALSE # process features for test_test set
```

### Tune the SVM model with cross-validation:
```{r}
tm_train=NA
tm_train <- system.time(tuned_parameters <- tune.svm(emotion_idx~., 
                                                     data = dat_train_pca_final, 
                                                     gamma = 10^(-5:-1), 
                                                     cost = c(30,35,40),
                                                     tunecontrol = tune.control(cross =12)
                                                     ))
summary(tuned_parameters)

```

```{r}
source("../lib/train_svm.R")
par_best=NULL
fit_train_final_svm <- train(dat_train_pca_final, tuned_parameters$best.parameters)
save(fit_train_final_svm, file="../output/fit_train_final.RData")


### Train accurancy:
source("../lib/test_svm.R")
load("../output/fit_train_final.RData")

if(run.test){
  pred_train <- test(fit_train_final_svm, dat_train_pca_final)
}
accu <- mean(dat_train_pca_final$emotion_idx == pred_train)
accu
# [1] 0.59

### SVM: Run test on test images
source("../lib/test_svm.R")
tm_test=NA
if(run.test){
  tm_test <- system.time(pred <- test(fit_train_final_svm, dat_test_pca_final))
}

### SVM: Run test_test on test images
source("../lib/test_svm.R")
tm_test=NA
if(run.test){
  load(file="../output/fit_train_final.RData")
  tm_test <- system.time(pred <- test(fit_train_final_svm, dat_test_pca_final))
}

### evaluation
accu <- mean(dat_test_pca_final$emotion_idx == pred)
cat("The accuracy of model:", "is", accu*100, "%.\n")
library(caret)
confusionMatrix(pred, dat_test_pca_final$emotion_idx)

### Summarize Running Time
### Prediction performance matters, 
### so does the running times for constructing features and for training the model, 
### especially when the computation resource is limited. 
cat("Time for training model=", tm_train[1], "s \n")
cat("Time for testing model=", tm_test[1], "s \n")

```


#### 4. GBM (*Baseline Model*)
* Tune GBM.
```{r}
hyper_grid <- expand.grid(
  shrinkage = c(.001, .01),
  interaction.depth = c(1, 3),
  n.minobsinnode = c(5, 10),
  bag.fraction = c(.65, .8), 
  optimal_trees = 0,               # a place to dump results
  min_RMSE = 0                     # a place to dump results
)

# randomize data
random_index <- sample(1:nrow(dat_train_pca_final), nrow(dat_train_pca_final))
random_train <- dat_train_pca_final[random_index, ]

# grid search 
for(i in 1:nrow(hyper_grid)) {
  
  # reproducibility
  set.seed(123)
  
  # train model
  gbm.tune <- gbm(
    formula =  emotion_idx~.,
    distribution = "multinomial",
    data = random_train,
    n.trees = 100,
    interaction.depth = hyper_grid$interaction.depth[i],
    shrinkage = hyper_grid$shrinkage[i],
    n.minobsinnode = hyper_grid$n.minobsinnode[i],
    bag.fraction = hyper_grid$bag.fraction[i],
    train.fraction = .75,
    n.cores = NULL, # will use all cores by default
    verbose = FALSE
  )
  
  # add min training error and trees to grid
  hyper_grid$optimal_trees[i] <- which.min(gbm.tune$valid.error)
  hyper_grid$min_RMSE[i] <- sqrt(min(gbm.tune$valid.error))
}


hyper_grid %>% 
  dplyr::arrange(min_RMSE) %>%
  head(10)
```

```{r}
source("../lib/train_gbm.R")
tm_train=NA
tm_train <- system.time(fit_train_baseline <- train(dat_train_pca_final, par = NULL))
save(fit_train_baseline, file="../output/fit_train_baseline_final.RData")
### Train Error
source("../lib/test_gbm.R")
load("../output/fit_train_baseline_final.RData")

tm_test=NA
if(run.test){
  tm_test <- system.time(pred_train <- test(fit_train_baseline, dat_train_pca_final))
}
labels = colnames(pred_train)[apply(pred_train, 1, which.max)]
accu <- mean(dat_train_pca_final$emotion_idx == labels)
accu


### GBM: Run test on test images

source("../lib/test_gbm.R")
tm_test=NA
if(run.test){
  tm_test <- system.time(pred <- test(fit_train_baseline, dat_test_pca_final))
}

### GBM: Run test_test on test images
source("../lib/test_gbm.R")
tm_test_test=NA
if(run.feature.test.test){
  load(file="../output/fit_train_baseline_final.RData")
  tm_test <- system.time(pred <- test(fit_train_baseline, dat_test_selected))
}

### Evaluation
labels = colnames(pred)[apply(pred, 1, which.max)]
accu <- mean(dat_test_pca_final$emotion_idx == labels)
cat("The accuracy of model:", "is", accu*100, "%.\n")
library(caret)
confusionMatrix(as.factor(labels), dat_test_pca_final$emotion_idx)


### Summarize Running Time
### Prediction performance matters, 
### so does the running times for constructing features and for training the model,
### especially when the computation resource is limited. 

#cat("Time for constructing training features=", tm_feature_train[1], "s \n")
#cat("Time for constructing testing features=", tm_feature_test[1], "s \n")
cat("Time for training model=", tm_train[1], "s \n")
cat("Time for testing model=", tm_test[1], "s \n")
```

#lda 
```{r}
source("../lib/train_lda.R")
tm_train=NA
tm_train <- system.time(fit_train_baseline <- train(dat_train_pca_final, par = NULL))
save(fit_train_baseline, file="../output/fit_train_baseline_final.RData")

### Train Error
source("../lib/test_lda.R")
load("../output/fit_train_baseline_final.RData")

tm_test=NA
if(run.test){
  tm_test <- system.time(pred_train <- test(fit_train_baseline, dat_train_pca_final))
}
accu <- mean(dat_train_pca_final$emotion_idx == pred_train$class)
accu
source("../lib/test_lda.R")
tm_test=NA
if(run.test){
  tm_test <- system.time(pred <- test(fit_train_baseline, dat_test_pca_final))
}

source("../lib/test_lda.R")
tm_test_test=NA
if(run.feature.test.test){
  load(file="../output/fit_train_baseline_final.RData")
  tm_test <- system.time(pred <- test(fit_train_baseline, dat_test_selected))
}

### Evaluation
accu <- mean(dat_test_pca_final$emotion_idx == pred$class)
cat("The accuracy of model:", "is", accu*100, "%.\n")
library(caret)
confusionMatrix(as.factor(labels), dat_test_pca_final$emotion_idx)
# ldatrain.model.start = proc.time()
# lda.model <- lda(emotion_idx ~ ., data=dat_train_pca) 
# ldatrain.model.end = proc.time()
# #time for training the model
# print(ldatrain.model.end - ldatrain.model.start)


### Summarize Running Time
### Prediction performance matters, 
### so does the running times for constructing features and for training the model,
### especially when the computation resource is limited. 

#cat("Time for constructing training features=", tm_feature_train[1], "s \n")
#cat("Time for constructing testing features=", tm_feature_test[1], "s \n")
cat("Time for training model=", tm_train[1], "s \n")
cat("Time for testing model=", tm_test[1], "s \n")
```